{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\face_alignment_test\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "import config\n",
    "from dataset import FaceLandmarksDataset, get_files\n",
    "from models import FaceAlignmentModel\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "files = get_files(config.TRAIN_FOLDERS)\n",
    "train_size = int(len(files) * config.TRAIN_VAL_SPLIT)\n",
    "train_files, val_files = random_split(files, [train_size, len(files) - train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff8e6f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\face_alignment_test\\venv\\lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FaceLandmarksDataset(train_files, train=True)\n",
    "val_dataset = FaceLandmarksDataset(val_files, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b44bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def heatmaps_to_keypoints_argmax(heatmaps):\n",
    "    \"\"\"\n",
    "    heatmaps: numpy (K, H_hm, W_hm) or torch tensor (K,H,W)\n",
    "    returns: coords (K,2) in heatmap-grid pixels (x, y)\n",
    "    \"\"\"\n",
    "    if isinstance(heatmaps, torch.Tensor):\n",
    "        heatmaps = heatmaps.detach().cpu().numpy()\n",
    "    K, H, W = heatmaps.shape\n",
    "    coords = np.zeros((K, 2), dtype=np.float32)\n",
    "    for i in range(K):\n",
    "        idx = heatmaps[i].argmax()\n",
    "        y = idx // W\n",
    "        x = idx % W\n",
    "        coords[i] = np.array([x, y], dtype=np.float32)\n",
    "    return coords\n",
    "\n",
    "def heatmaps_to_keypoints_softargmax_tensor(heatmaps_tensor, beta=100.0):\n",
    "    \"\"\"\n",
    "    heatmaps_tensor: torch tensor (B=1,K,H,W) or (K,H,W)\n",
    "    returns: numpy (K,2) coords in heatmap-grid pixels (x,y)\n",
    "    Soft-argmax (differentiable); useful for subpixel refinement.\n",
    "    \"\"\"\n",
    "    single = False\n",
    "    if heatmaps_tensor.ndim == 3:\n",
    "        heatmaps_tensor = heatmaps_tensor.unsqueeze(0)  # 1,K,H,W\n",
    "        single = True\n",
    "    B, K, H, W = heatmaps_tensor.shape\n",
    "    h = F.softmax(heatmaps_tensor.view(B, K, -1) * beta, dim=-1).view(B, K, H, W)\n",
    "    xs = torch.linspace(0, W-1, W, device=heatmaps_tensor.device, dtype=heatmaps_tensor.dtype)\n",
    "    ys = torch.linspace(0, H-1, H, device=heatmaps_tensor.device, dtype=heatmaps_tensor.dtype)\n",
    "    xs = xs.view(1,1,1,W)\n",
    "    ys = ys.view(1,1,H,1)\n",
    "    x = (h * xs).sum(dim=(2,3))  # B, K\n",
    "    y = (h * ys).sum(dim=(2,3))\n",
    "    coords = torch.stack([x, y], dim=-1)  # B, K, 2 (x,y)\n",
    "    coords = coords.cpu().numpy()\n",
    "    if single:\n",
    "        return coords[0]\n",
    "    return coords  # (B,K,2)\n",
    "\n",
    "def hm_coord_to_resized(coord_hm, img_size_resized, hm_size):\n",
    "    # coord_hm: (2,) x,y in heatmap pixels\n",
    "    H_resized, W_resized = img_size_resized\n",
    "    H_hm, W_hm = hm_size\n",
    "    x_resized = coord_hm[0] * (W_resized / W_hm)\n",
    "    y_resized = coord_hm[1] * (H_resized / H_hm)\n",
    "    return np.array([x_resized, y_resized], dtype=np.float32)\n",
    "\n",
    "def resized_to_orig(coord_resized, crop_box, scale):\n",
    "    # crop_box = [x1, y1, x2, y2], scale = [scale_x, scale_y]\n",
    "    x_orig = coord_resized[0] * scale[0] + crop_box[0]\n",
    "    y_orig = coord_resized[1] * scale[1] + crop_box[1]\n",
    "    return np.array([x_orig, y_orig], dtype=np.float32)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def visualize_sample(sample, show=True, out_path=None, top_k=5):\n",
    "    \"\"\"\n",
    "    sample: dict from dataset\n",
    "    expects:\n",
    "      - image: tensor C,H,W (resized and normalized)\n",
    "      - keypoints_px: tensor K,2 in resized pixels (or landmarks)\n",
    "      - keypoints_norm: tensor K,2 in [0,1]\n",
    "      - heatmaps: tensor K,H_hm,W_hm (or None)\n",
    "      - crop_box: tensor [x1,y1,x2,y2]\n",
    "      - scale_unnorm: [orig_h, orig_w] or scale factors — adapt below\n",
    "      - orig_size / pil image available externally if needed\n",
    "    \"\"\"\n",
    "    img_t = sample['image'].cpu().numpy().transpose(1,2,0)  # H,W,C (normalized)\n",
    "    # unnormalize for display:\n",
    "    mean = np.array(getattr(config, \"MEAN\", [0.485,0.456,0.406]))\n",
    "    std = np.array(getattr(config, \"STD\", [0.229,0.224,0.225]))\n",
    "    img_disp = (img_t * std + mean)\n",
    "    img_disp = np.clip(img_disp, 0, 1)\n",
    "\n",
    "    H_resized, W_resized = img_disp.shape[:2]\n",
    "\n",
    "    kps_px = sample.get('keypoints_px', sample.get('landmarks')).cpu().numpy()  # K,2\n",
    "    kps_norm = sample.get('keypoints_norm', None)\n",
    "    if kps_norm is not None:\n",
    "        kps_norm = kps_norm.cpu().numpy()\n",
    "\n",
    "    heatmaps = sample.get('heatmaps', None)\n",
    "    if heatmaps is not None:\n",
    "        if isinstance(heatmaps, torch.Tensor):\n",
    "            hm = heatmaps.cpu().numpy()  # K,H_hm,W_hm\n",
    "        else:\n",
    "            hm = heatmaps\n",
    "\n",
    "    crop_box = sample['crop_box'].cpu().numpy()\n",
    "    scale = sample['scale'].cpu().numpy()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3 if heatmaps is not None else 2, figsize=(15,5))\n",
    "\n",
    "    # 1) resized image + GT keypoints\n",
    "    ax = axs[0]\n",
    "    ax.imshow(img_disp)\n",
    "    ax.set_title(\"resized image with GT keypoints (resized coords)\")\n",
    "    # plot all keypoints\n",
    "    valid = (kps_px[:,0] >= 0) & (kps_px[:,1] >= 0)\n",
    "    ax.scatter(kps_px[valid,0], kps_px[valid,1], s=8, c='lime', marker='o')\n",
    "    for i, (x,y) in enumerate(kps_px):\n",
    "        if valid[i]:\n",
    "            ax.text(x+1, y+1, str(i), color='yellow', fontsize=6)\n",
    "\n",
    "    # 2) original crop (reconstructed) + mapped GT\n",
    "    ax2 = axs[1]\n",
    "    # to reconstruct original crop for display, we need original full image.\n",
    "    # We'll create a blank canvas and show where crop would sit\n",
    "    canvas = np.ones((int(sample['orig_size'][0].item()), int(sample['orig_size'][1].item()), 3), dtype=np.float32) * 0.5\n",
    "    # draw crop region from resized image scaled back to crop size\n",
    "    crop_w = int((crop_box[2]-crop_box[0]+1))\n",
    "    crop_h = int((crop_box[3]-crop_box[1]+1))\n",
    "    # resize img_disp to crop size for visualization\n",
    "    img_crop_vis = cv2.resize((img_disp*255).astype(np.uint8), (crop_w, crop_h))\n",
    "    # place into canvas\n",
    "    x1,y1 = int(crop_box[0]), int(crop_box[1])\n",
    "    canvas[y1:y1+crop_h, x1:x1+crop_w] = img_crop_vis / 255.0\n",
    "    ax2.imshow(canvas)\n",
    "    ax2.set_title(\"reconstructed original image with GT mapped back\")\n",
    "    # map resized keypoints -> orig and plot\n",
    "    kps_resized = kps_px.copy()\n",
    "    # handle invisible:\n",
    "    for i in range(kps_resized.shape[0]):\n",
    "        if kps_resized[i,0] < 0:\n",
    "            continue\n",
    "        x_res, y_res = kps_resized[i]\n",
    "        x_orig = x_res * scale[0] + crop_box[0]\n",
    "        y_orig = y_res * scale[1] + crop_box[1]\n",
    "        ax2.scatter([x_orig], [y_orig], c='cyan', s=6)\n",
    "        # optionally annotate indices:\n",
    "        # ax2.text(x_orig+1, y_orig+1, str(i), color='white', fontsize=6)\n",
    "\n",
    "    # 3) heatmap overlay for a few keypoints + peaks\n",
    "    if heatmaps is not None:\n",
    "        ax3 = axs[2]\n",
    "        # show sum of heatmaps upsampled to resized size (for visual)\n",
    "        sum_hm = np.sum(hm, axis=0)  # H_hm, W_hm\n",
    "        sum_hm_resized = cv2.resize(sum_hm, (W_resized, H_resized))\n",
    "        ax3.imshow(img_disp, alpha=0.8)\n",
    "        ax3.imshow(sum_hm_resized, cmap='jet', alpha=0.5)\n",
    "        ax3.set_title(\"sum heatmap overlay\")\n",
    "        # draw argmax peaks for first N keypoints\n",
    "        peaks = heatmaps_to_keypoints_argmax(hm)\n",
    "        for i in range(min(len(peaks), top_k)):\n",
    "            px_hm = peaks[i]\n",
    "            px_res = hm_coord_to_resized(px_hm, (H_resized, W_resized), (hm.shape[1], hm.shape[2]))  # hm shape is (K,H,W): careful\n",
    "            # note: our helper expects hm shape ordering accordingly\n",
    "            ax3.scatter(px_res[0], px_res[1], c='red', s=20, marker='x')\n",
    "            ax3.text(px_res[0]+1, px_res[1]+1, str(i), color='red', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if out_path:\n",
    "        plt.savefig(out_path, dpi=150)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "def compute_nme_from_sample(sample):\n",
    "    \"\"\"\n",
    "    Проверка: heatmaps -> argmax -> map back -> compare with original GT\n",
    "    Возвращает mean NME и per-keypoint errors (in pixels and normalized).\n",
    "    \"\"\"\n",
    "    kps_px = sample['keypoints_px'].cpu().numpy()   # resized pixels (GT)\n",
    "    heatmaps = sample['heatmaps']\n",
    "    if heatmaps is None:\n",
    "        raise RuntimeError(\"No heatmaps in sample\")\n",
    "    if isinstance(heatmaps, torch.Tensor):\n",
    "        hm = heatmaps.cpu().numpy()\n",
    "    else:\n",
    "        hm = heatmaps\n",
    "\n",
    "    # get peaks in heatmap grid (x_hm,y_hm)\n",
    "    peaks_hm = heatmaps_to_keypoints_argmax(hm)  # K,2 (x,y) in hm grid\n",
    "\n",
    "    # map peaks -> resized\n",
    "    H_resized, W_resized = sample['image'].shape[1], sample['image'].shape[2]\n",
    "    H_hm, W_hm = hm.shape[1], hm.shape[2]\n",
    "    peaks_resized = np.zeros_like(peaks_hm)\n",
    "    peaks_resized[:,0] = peaks_hm[:,0] * (W_resized / W_hm)\n",
    "    peaks_resized[:,1] = peaks_hm[:,1] * (H_resized / H_hm)\n",
    "\n",
    "    # compare only visible GT keypoints (kps_px >=0)\n",
    "    vis = (kps_px[:,0] >= 0) & (kps_px[:,1] >= 0)\n",
    "    diffs = np.linalg.norm(peaks_resized[vis] - kps_px[vis], axis=1)  # pixels in resized image\n",
    "    mean_px = np.mean(diffs) if diffs.size > 0 else 0.0\n",
    "\n",
    "    # normalized error relative to sqrt(H*W) of face_rect (as in your metric)\n",
    "    face_rect = sample['face_rect'].cpu().numpy()\n",
    "    Hf = face_rect[3] - face_rect[1]\n",
    "    Wf = face_rect[2] - face_rect[0]\n",
    "    norm = np.sqrt(Hf * Wf) if Hf>0 and Wf>0 else 1.0\n",
    "    diffs_orig = diffs * ( (sample['scale'][0].item() + sample['scale'][1].item())/2.0 )  # approx map pixels->orig (better map each axis)\n",
    "    # better: map peaks_resized -> orig using scale + crop_box and compute distance in original pixels to GT original\n",
    "    # but we can estimate:\n",
    "    mean_norm = mean_px / max(1e-6, np.sqrt(H_resized * W_resized))  # just check smallness\n",
    "    return {\n",
    "        \"mean_px_resized\": mean_px,\n",
    "        \"mean_norm_resized\": mean_norm,\n",
    "        \"per_point_px\": diffs,\n",
    "        \"n_visible\": int(np.sum(vis))\n",
    "    }\n",
    "\n",
    "from random import randint\n",
    "\n",
    "def quick_check_dataset(ds, n=10):\n",
    "    for i in range(n):\n",
    "        idx = randint(0, len(ds)-1)\n",
    "        sample = ds[idx]\n",
    "        visualize_sample(sample, show=True)\n",
    "        stats = compute_nme_from_sample(sample)\n",
    "        print(f\"sample {idx}: mean_px_resized={stats['mean_px_resized']:.3f}, n_visible={stats['n_visible']}\")\n",
    "\n",
    "quick_check_dataset(train_dataset, n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
